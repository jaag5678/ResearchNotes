\documentclass[notes, xcolor = dvipsnames]{beamer}

\usetheme{Warsaw}

\usepackage{amsmath}
\usepackage{graphicx}

\title{Memory Barriers: A Hardware view for Software Hackers}
\subtitle{Paul E. McKenney}

\author{Presented by \\ Akshay Gopalakrishnan}

\begin{document}
  
    \begin{frame}
        
        \maketitle
    \end{frame}


    \begin{frame}{Introduction}
        
        \begin{itemize}
            \item This paper represents the inner working of hardware that results in several non-sequential behaviors of our concurrent programs
            \item The paper is rife with examples as well as showcasing the reasons for having such hardware features which in turn help in our programs performing better.
            \item Along with the positives the author also carefully cautions why such rampant changes for performance might result in highly non-trivial behaviors being showcased by the hardware running our programs.
            \item The paper concludes by discussing the then versions of several concurrent hardware that exhibit different non-sequential behaviors.
        \end{itemize}

    \end{frame}

    \begin{frame}{Cache structures}
        
        \begin{figure}
            \makebox[\textwidth][c]{
                \includegraphics[scale=0.3]{CacheStructure.png}
            }
        \end{figure}

        \begin{itemize}
            \item An extra chunk of memory local to a given cpu (or multiple cpus in bigger systems).
            \item Data read from memory will also be saved in the cache if there is space. 
            \item Any subsequent accesses to the same memory will be first looked at in the cache and if not present, from the main memory.
        \end{itemize}

    \end{frame}

    \begin{frame}{The usefullness of Caches}
        
        \begin{itemize}
            \item Used for faster access of memory. 
            \item Useful when a single shared memory location is being accessed several times but not changed. 
            \item Need to read from main memory which is at least 10x times slower than accessing caches.
            \item Overall performance of program is significantly improved. 
        \end{itemize}

    \end{frame}

    \note{
        In modern systems there are multiple cache levels that exist, each of which is based on the scope. 
        For instance, L1 cache is local to just one core. Whereas L2 is to multiple cores in the same processor (could also be others). 
        All this layering is done for performance, part of the reason why we have such highly non-trivial behaviors of our concurrent programs.
    }

    \begin{frame}{THe MESI protocol}
        
        \begin{itemize}
            \item Multiple caches need to be in synchronization to ensure no stale data in caches exist. 
            \item Caches can communicate with each other via the interconnect network.
            \item We require a protocol to ensure that caches lines are updated accordingly. 
        \end{itemize}

        An example of such a protocol is MESI (Modified Exclusive Shared and Invalid).
        \begin{itemize}
            \item Modified - cache line has the upto date data which resides in memory and the data has been stored by the corresponding CPU. 
            \item Exclusive - cache line is not updated with the recent memory store done by the corresponding CPU. 
            \item Shared  - cache line is in read-only state (CPU needs to consult with other CPU caches before being able to write to it)
            \item Invalid - "empty" cache line and new data can be put here. 
        \end{itemize}


    \end{frame}

    \note{
        Modified state is when my CPU is writiing to memory some data as well as duly updated the cache line. Now this line has the only copy of the latest data in memory. 
        Exlcusive is one step behind modified state, wherein the CPU has updated memory, but not just its cache line. 
        Shared state is when more than one cache line has the same data of memory. This only means, if I want to change one cache line, I must inform the others too. 
        Invalid state can contain any stale data that is never going to be read by the CPU (as it is stale).
    }

    \begin{frame}{MESI Protocol Messages}

        The following messages are passed by a cache line to other caches in the system. 
        \begin{itemize}
            \item Read - Contains the physical address of the cache line to be read. 
            \item Read Response - Contains the data requested by a previous Read message.
            \item Invalidate - Contains the physical address of the cache line to be invalidated. 
            \item Invalidate Acknowledge - CPU receiving an Invalidate message must respond with this message once the specfied cache line is invalidated.
            \item Read Invalidate - Does the action of both Read and Invalidate in one message. 
            \item Writeback - Contains both the address and the data tobe written back to memory (could also implicitly update other cache lines with this).
        \end{itemize}
        
    \end{frame}

    \begin{frame}{Example of Cache Communication}

        The following table represents a sequence of actions done by CPU and the different states (MESI) of the caches after the action has been done. 
        \begin{figure}
            \makebox[\textwidth][c]{
                \includegraphics[scale=0.2]{MESI_Example.png}
            }
        \end{figure}
        
    \end{frame}

    \begin{frame}{Sequence 0 to 2}

        The 0th sequence represents the default state of cache before being used. 
        Each cache line is set to "Invalid" state. 

        The 1st sequence represents a load done by CPU 0 to fetch data from address 0. 
        The content in stored in CPU0 cache and the state changes to "Shared".

        The 2nd sequences represents a load done by CPU 0 to fethc data from address 0.
        The content is stored in CPU1 cache and the state changes to "Shared".
        
    \end{frame}

    \begin{frame}{Sequence 3 to 5}

        The 3rd sequence represents a load done by CPU 0 to fetch data from address 8.
        This implicity means to Invalidate one's own cache line by sending an invalidate message to it. 
        This gives space to store data from address 0, which now is in the "Shared" state.

        The 4th sequence represents an RMW done by CPU 2 on address 0.
        Before it can do this, it needs to invalidate other caches having data on this address by sending "Invalidate" message.
        Once that is done, it's own cache (CPU 2) is set to "Exclusive" state, while others which had data at address 0 to "Invalid".
        
        The 5th sequence represents the actual store done by CPU 2 (as part of RMW).
        This changes its own cache to state "Modified" and sets the memory of address 0 to "Invalid".
    \end{frame}

    \begin{frame}{Sequence 6 and 7}

        The 6th sequence represents CPU 1 performing an atomic write to data at Address 0.
        Since CPU 2 has its cache in modified state, the increment needs to change that value, while also invalidating their cache. 
        So a "Read Invalidate" message is sent to each cache line, get the updated store value and increment it by 1.
        Now it sets its own cache line (CPU 1) to modified state. 
        While other caches having data at address 0 is set ot invalidate. 

        The 7th sequence represents the actual commiting of the new data to memory. 
        This can either be done by actually issuing a writeback or forcing the cache to make space for other address data (via a Load).
        Here, a Load is issued for address 0 by CPU 1, which forces a writeback to address 0.
        The value at memory address 0 is updated and the state becomes "Valid".
        Meanwhile the cache line of CPU 1 has a "Shared" state.
        
    \end{frame}


    \begin{frame}{Example}
        
    \end{frame}

    \begin{frame}{Need for Write Buffers}
        
    \end{frame}

    \begin{frame}{Added Complications}
        
    \end{frame}

    \begin{frame}{Example}

    \end{frame}

    \begin{frame}{Here comes Write Memory Barriers}
        
    \end{frame}

    \begin{frame}{Need for Invalidate Queues}
        
    \end{frame}

    \begin{frame}{Added Complications}
        
    \end{frame}

    \begin{frame}{Example}
        
    \end{frame}

    \begin{frame}{Here comes Read Memory Barriers}
        
    \end{frame}

    \begin{frame}{Barrier instructions offered by Linux}
        
    \end{frame}

    \begin{frame}{Hardware Example: Alfa}
        
    \end{frame}

    \begin{frame}{Hardware Example: x86}
    
    \end{frame}

    \begin{frame}{Conclusion}
        
    \end{frame}

\end{document}