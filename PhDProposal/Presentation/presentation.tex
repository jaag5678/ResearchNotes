\documentclass[notes, xcolor = dvipsnames]{beamer}

\usetheme{Warsaw}

\usepackage{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}

\title{Towards Transformational Specification of Relaxed Memory Models}

\author{Presentation by Akshay Gopalakrishnan \\ Supervised by Clark Verbrugge}

\begin{document}
    
    \begin{frame}

        \maketitle

    \end{frame}

    
    \begin{frame}{Introduction}

        %What are memory models.
            % Give examples of SB, MP, LB, etc and relate them to existing hardwares 
        %Common problems with them addressed for each model designed 
            %-- eg: Compiler mappings correctness, Program Transformations, Robustness, Verification, etc 
        %Existing specification of models
            % Axiomatic per execution style
            % Operational 
            % Recent one -- Event structures
        %Importance of such semantic models.
            % Formal mathematical definitions of intended behaviors.
            % Verification - not our focus.
            % Help prove program transformations sound. 
            % Identify other problems with the model -- Out-of-thin-air
        %What it is lacking. 
            % Often not that intuitive
            % AXiomatic model involves several relations over events and the axioms itself are complex irreflexivity relations.
            % Operational models are abstract and could be intuitive but difficult to rely on while programming. 
            % Each model has to be proven separately for program transformations -- (WHAT DOES THIS MEAN?)

    \end{frame}

    \begin{frame}{Intro}
        
        Almost every system we use for our day-to-day lives rely on concurrent computation. 
        Right from our mobile phones to our personal desktop which can seemingly perform multiple tasks at the same time, concurrent computations have become part of our daily life.
        The amount of performance concurrent computation has given us is something that is near impossible to part with. 
        But an important question remains, can we understand and utilize concurrency at its best for the various domain specific compuatations we intend to do?
    
    \end{frame}

    \begin{frame}{What are Memory Models?}
    
        Concurrent programs take advantage of \textit{out-of-order} execution. 
        Intuitively, this means that more than one unrelated computations can be done ``simultaneously'' without having any fixed order in which they should happen.
        This results in concurrent programs having multiple different outcomes.
        In terms of concurrenct compuations using shared memory, the possible outcomes are described by
        a \textit{memory consistency model}.
    
    \end{frame}

    \begin{frame}{The inclination towards Sequential Reasoning}

        Despite the elaborate different ways in which we can think of writing programs that leverage the \textit{out-of-order} notion, most programmers are accustomed to reasoning about computations sequentially. 
        Sequential Consistency(SC), which was a memory model first formulated by Lamport et al.~\cite{Lamport79}, gives programmers this exact sequential reasoning for their programs running in a multiprocessor environment.
        
    \end{frame}

    \begin{frame}{Current Hardwares - the thrist for performance}

        Though SC seems to be a very intuitive way to reason about programs using shared memory, it does not reflect how different processors do their computation.
        Hardwares in today's era have multiple features such as caches, read/write buffers, speculative execution, etc. which are designed to give us the performance we quite often take for granted these days.
        Usage of such features however, does not respect SC reasoning.
        
    \end{frame}

    \begin{frame}{Example: Message Passing}
        
    \end{frame}

    \begin{frame}{Example: Store Buffering}
        
    \end{frame}

    \begin{frame}{Example: Load Buffering}
        
    \end{frame}

    \begin{frame}{Example: Non-Multi-Copy Atomic Behavior}
        
    \end{frame}

    %Place some Misc example from POWER paper if required.

    %------------------------------------------------------------------------------------------------------------------------------------

    \begin{frame}{Common Problems Associated with Relaxed Memory Models}
        
        \begin{itemize}
            \item Informal specifications.
            \item Correctness of Compiler Mappings.
            \item Correctness of Program Transformations.
            \item Robustness Analysis.
            \item Compositional Correctness.
            \item Verification. 
        \end{itemize}
        
        %Hardware models have historically suffered from informal specifications. 
        %This makes it impossible to carefully use program constructs to use such relaxed behaviors.
        %In addition, having relaxed memory models for high level languages have brought upon concerns regarding correct Compiler Mappings to ensure the hardware does not execute our program incorrectly.
        %Additionally, compiler optimizations also have become a topic of correctness checking as almost all optimizations designed for performance are made for only sequential code. 
        %Thus, proving such optimizations at the base level (eg: Simple reordering, Elimination, etc) is required to assess the correctness of elaborate transformations like partial redundancy elimination, loop invariant code motion, etc. 

    \end{frame}

    \begin{frame}{Informal Specifications}
        
    \end{frame}

    \begin{frame}{Correctness of Compiler Mappings}
        
    \end{frame}

    \begin{frame}{Correctness of Program Transformations}
        
    \end{frame}

    \begin{frame}{Robustness}
        
    \end{frame}

    \begin{frame}{Compositional Correctness}
    
    \end{frame}

    \begin{frame}{Verification}
        
    \end{frame}

    %-----------------------------------------------------------------------------------------------------------------------

    \begin{frame}{Constructing models using program transformations: Goal}

        %Primary vision 
            % Towards identifying minimal set of transformations that can identify all weak memory behaviors
            % This minimal set can then be used to construct all possible memory consistency models.
            %Minimal set to perform testing of such concurrency models. 

        %Having a transformational model 
            % We start by designing memory models specified by a set of transformations allowed over a base model 
            % Doing this will give us a hierarchical structure of memory models w.r.t. program transfomraitons.
            % Intuitive to rely on by able to program justifying each outcome by some combination of program transformations.
    \end{frame}

    \begin{frame}{Idea}

        %A way to construct such models using only set of transformations.

        %A baseline model to be considered - Currently a per-execution axiomatic model (set of axioms)
            %Base model does not allow the set of transformations we would want to allow. 
            %Allowing a transformation will bring changes to set of axioms (irreflexivity relations may change) or relax certain partial orders defined for the axioms.
            %Resulting model is the new one with the program transformations. 
        %Each transformed model is to be proved weaker than the original model in terms of observable behaviors.
        % The transformation added also to be proved sound under the transformed model.
        % Model also to be proved optimal/complete (ask viktor/clark/mark about this wording) to ensure the "weakening" is not too much of the base model 

    \end{frame}

    \begin{frame}{Simplicity}

        %Compositional in nature 
            %Intend to investigate whether one can construct models by taking union of their program transformations 
                %Model M1 with set T1 plus model M2 with set T2 == Model M3 with set T1 + T2.
            %Having a hierarchical structure of such memory models purely built on program transformations. 
             
        %PErhaps attach a figure here.
            % A venn diagram showing clear subset relations that hold in terms of observable behaviors of base model vs other transformed models.
            % Compare and contrast this with the Java memory model diagram shared by Clark. 
    \end{frame}

    \begin{frame}{Possible Advantages - Theoretical}

        %Compiler Correctness - mapping proofs.
        %Robustness conditions to enforce portability of programs.
        %Compositional correctness

        %For each of them, prepare a set of slides
    \end{frame}

    \begin{frame}{Compiler Correctness}
        
        %If source and target model are both defined using base model M
            % Then consider cases of the transformation sets 
            % Transcribe from ipad notes of this

    \end{frame}

    \begin{frame}{Robustness Conditions}
        
        %Analyze directly the transformation sets 


    \end{frame}

    \begin{frame}{Compositional Correctness}
        
        % Compositonal reasoning can be bypassed if 
            % Both memory models under which a single program is going to be run in parts can be described using same base model M.
            % Take the intersection of their transformation sets and the intersection model is what we need to check correctness with. 

    \end{frame}

    \begin{frame}{Elements to define models} 

        %Need 
            %A precise set of axiomatic events - R/W/U/Frr/Frw/Fwr/Fww
            %Atomic accesses U 
            %Non-Atomic variants R/W
            %Fence variants Frr/Frw/Fwr/Fww
            %Misc instructions - ask viktor/clark/mark

    \end{frame}

    \begin{frame}{Constructing base model}

        %Start with a standard base model (eg: Sequential consistency)
        %Define the base model using our elements 
        %Prove equivalence to existing axiomatic model in literature. 

    \end{frame}

    \begin{frame}{Establishing Equivalence} 

        %Build various models using base model and different sets of transformations.
        %Test equivalence to existing standard models (TSO, RA, ARM, POWER, etc) using our approach.
        %If equivalent, we have a more intuitive model for each of the standard ones. 
        %If not, we establish the possible space of models that can be constructed this way. 

    \end{frame}

    %-------------------------------------------------------------------------------------------

    \begin{frame}{Challenges: Part 1}

        %Identify the axiomatic elements using which we construct our base models and the transformational ones
            %Should technically account for most(ideally all) features in existing standard relaxed memory models
            %Elements should be independent of each other. (dependency will create redundancy while constructing axioms)

            %Can start off with just simple read/writes and four types of fences as defined in Doug Lea's cookbook.

        %Identify different partial/total orders required
            %ideally start off with preliminary ones.
            %Build as required.
            %May make the model more complicated aS we add on program transformations

            %Start with po, rf, mo, rb. 
            %Next one should strongly be hb.
 
    \end{frame}
    
    \begin{frame}{Challenges: Part 2}

        %Set of transformations
            %Mostly local 
                %Also need to identify the granularity in each transformation (eg: Reordering how many variants? R-R, R-W, W-R, W-W or more than that)
                %Other than reordering, elimination, introduction what other local transformations are base ones?
                %For each local transformation, make sure that it is only w.r.t consecutive memory accesses (or redundant fences between them)
                %This is because the non-consecutive one is just a direct inductive variant of the consecutive ones. 
            
            %Possible non-local 
                %Sequentialization - merging code of two threads in either order.
                %Parallelization - splitting a code into two threads (may not be safe in any sense)
                %Other possibilities? Need to tread carefully as such transformations are non-trivial to understand and may affect our model construction heavily. 
                %Having a formal definition of when we do such transformations is going to be a non-trivial endeavor. There could be many variants.
                %Ideally, the goal is to address non-local transformations only when the local ones are all wrapped up formally and proven.

    \end{frame}

    \begin{frame}{Challenges: Part 3}

        %Defining what a transformation does.
            %based on definition, changing axiomatic definitions or modifying axioms of irreflexivity. 
            %Will definitely first change the axioms, then for convenience can add additional definitions of partial orders (like extended coherence order, writes before and what-not)
            %May need Clark's help for this phase as it can quickly go out of control.

        %Set of axioms
        %Can have various axiomatic models for same base model
        %Set of axioms should as far as possibly reflect the variants of transformations disallowed by the model itself.
        %We can start off with taking model definitions from Viktor and Ori's work.

        %In that way, allowing a transformation will ensure minimal changes in the axiomatic definition (eg: just removal of one axiom)
        %True, but it may be difficult to define the model itself as a whole, so it will be a delicate interplay between both.

    \end{frame}

    \begin{frame}{Challenges: Part 4}

        %Possibly, existing standard models may not be defined in such a way
        %Problem comes as it may be that base model M allows set T and transformed model allows T + T1, but standard model allows only T1. 
        %Then should our base model be that specific standard model? 

        %Refer to Viktor and Ori's work for more insight on this
        %Their work has proof (by counter example) that TSO cannot be defined the way we are going about, as Sequentialization is unsound under TSO but sound under SC. 
        %However, we did notice that while they discarded the possibility of defining RA being reducible (by applying sound transformations) to SC or TSO, the counter examples could be easily explained via coherence. 
        %Is it then that Coherence model is reducible to RA and models like POWER? (can perhaps ask Viktor and maybe consider doing this as a collaborative work with him)

        %Additionally, it could also be that RA can be considered as a Base model to derive Coherence by adding transformations. 
        %Is it then possible to observe any relations between multiple base models in terms of their transformation sets? 
        %This is yet to be seen and can provide really important insight, which Viktor and Ori's work has just scraped about.   

    \end{frame}

    %Related work needs to be listed perhaps?
    \begin{frame}{Misc}

    \end{frame}

    \begin{frame}{Thank you}
        Questions?
    \end{frame}

\end{document}